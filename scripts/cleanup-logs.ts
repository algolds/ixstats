#!/usr/bin/env tsx

/**
 * IxStats Log and Report Cleanup Script
 *
 * This script performs the following cleanup operations:
 * 1. Deletes log files and audit reports older than 3 days
 * 2. Truncates large files (>10,000 lines) to keep only the most recent entries
 * 3. Removes duplicate or redundant audit reports
 * 4. Cleans up temporary files and node_modules logs
 *
 * Usage: npm run cleanup:logs
 */

import { execSync } from "child_process";
import { readFileSync, writeFileSync, unlinkSync, statSync, readdirSync } from "fs";
import { join, dirname } from "path";
import { UserLogger } from "../src/lib/user-logger";

const PROJECT_ROOT = process.cwd();
const REPORTS_DIR = join(PROJECT_ROOT, "scripts/audit/reports");
const MAX_LINES = 10000;
const MAX_AGE_DAYS = 3;

interface CleanupStats {
  deletedFiles: number;
  truncatedFiles: number;
  totalSpaceSaved: number;
  errors: string[];
}

class LogCleanup {
  private stats: CleanupStats = {
    deletedFiles: 0,
    truncatedFiles: 0,
    totalSpaceSaved: 0,
    errors: [],
  };

  async run(): Promise<void> {
    console.log("üßπ Starting IxStats log and report cleanup...\n");

    try {
      // 1. Clean up old audit reports
      await this.cleanupOldReports();

      // 2. Clean up large files
      await this.truncateLargeFiles();

      // 3. Clean up duplicate reports
      await this.removeDuplicateReports();

      // 4. Clean up log files
      await this.cleanupLogFiles();

      // 5. Clean up node_modules logs
      await this.cleanupNodeModulesLogs();

      // 6. Clean up user logs
      await this.cleanupUserLogs();

      // 7. Display summary
      this.displaySummary();
    } catch (error) {
      console.error("‚ùå Cleanup failed:", error);
      this.stats.errors.push(String(error));
    }
  }

  private async cleanupOldReports(): Promise<void> {
    console.log("üìä Cleaning up old audit reports...");

    try {
      const files = readdirSync(REPORTS_DIR);
      const cutoffDate = new Date();
      cutoffDate.setDate(cutoffDate.getDate() - MAX_AGE_DAYS);

      for (const file of files) {
        if (!file.endsWith(".json")) continue;

        const filePath = join(REPORTS_DIR, file);
        const stats = statSync(filePath);

        if (stats.mtime < cutoffDate) {
          const size = stats.size;
          unlinkSync(filePath);
          this.stats.deletedFiles++;
          this.stats.totalSpaceSaved += size;
          console.log(`  üóëÔ∏è  Deleted old report: ${file} (${this.formatBytes(size)})`);
        }
      }
    } catch (error) {
      this.stats.errors.push(`Failed to cleanup old reports: ${error}`);
    }
  }

  private async truncateLargeFiles(): Promise<void> {
    console.log("üìè Truncating large files...");

    try {
      const files = readdirSync(REPORTS_DIR);

      for (const file of files) {
        if (!file.endsWith(".json")) continue;

        const filePath = join(REPORTS_DIR, file);
        const content = readFileSync(filePath, "utf8");
        const lines = content.split("\n");

        if (lines.length > MAX_LINES) {
          const originalSize = content.length;

          // Keep the last MAX_LINES lines
          const truncatedContent = lines.slice(-MAX_LINES).join("\n");
          writeFileSync(filePath, truncatedContent);

          const newSize = truncatedContent.length;
          const spaceSaved = originalSize - newSize;

          this.stats.truncatedFiles++;
          this.stats.totalSpaceSaved += spaceSaved;
          console.log(
            `  ‚úÇÔ∏è  Truncated ${file}: ${lines.length} ‚Üí ${MAX_LINES} lines (${this.formatBytes(spaceSaved)} saved)`
          );
        }
      }
    } catch (error) {
      this.stats.errors.push(`Failed to truncate large files: ${error}`);
    }
  }

  private async removeDuplicateReports(): Promise<void> {
    console.log("üîÑ Removing duplicate reports...");

    try {
      const files = readdirSync(REPORTS_DIR);
      const fileGroups = new Map<string, string[]>();

      // Group files by type (consolidated, prod-issues, live-wiring)
      for (const file of files) {
        if (!file.endsWith(".json")) continue;

        let type = "other";
        if (file.startsWith("consolidated-")) type = "consolidated";
        else if (file.startsWith("prod-issues-")) type = "prod-issues";
        else if (file.startsWith("live-wiring-report-")) type = "live-wiring";

        if (!fileGroups.has(type)) {
          fileGroups.set(type, []);
        }
        fileGroups.get(type)!.push(file);
      }

      // For each type, keep only the 3 most recent files
      for (const [type, files] of fileGroups) {
        if (files.length <= 3) continue;

        // Sort by modification time (newest first)
        const sortedFiles = files.sort((a, b) => {
          const statA = statSync(join(REPORTS_DIR, a));
          const statB = statSync(join(REPORTS_DIR, b));
          return statB.mtime.getTime() - statA.mtime.getTime();
        });

        // Delete older files
        const filesToDelete = sortedFiles.slice(3);
        for (const file of filesToDelete) {
          const filePath = join(REPORTS_DIR, file);
          const size = statSync(filePath).size;
          unlinkSync(filePath);
          this.stats.deletedFiles++;
          this.stats.totalSpaceSaved += size;
          console.log(`  üóëÔ∏è  Removed duplicate ${type}: ${file} (${this.formatBytes(size)})`);
        }
      }
    } catch (error) {
      this.stats.errors.push(`Failed to remove duplicates: ${error}`);
    }
  }

  private async cleanupLogFiles(): Promise<void> {
    console.log("üìù Cleaning up log files...");

    try {
      // Clean up dev.log if it's too large
      const devLogPath = join(PROJECT_ROOT, "dev.log");
      try {
        const content = readFileSync(devLogPath, "utf8");
        const lines = content.split("\n");

        if (lines.length > MAX_LINES) {
          const originalSize = content.length;
          const truncatedContent = lines.slice(-MAX_LINES).join("\n");
          writeFileSync(devLogPath, truncatedContent);

          const spaceSaved = originalSize - truncatedContent.length;
          this.stats.truncatedFiles++;
          this.stats.totalSpaceSaved += spaceSaved;
          console.log(
            `  ‚úÇÔ∏è  Truncated dev.log: ${lines.length} ‚Üí ${MAX_LINES} lines (${this.formatBytes(spaceSaved)} saved)`
          );
        }
      } catch (error) {
        // dev.log might not exist, that's okay
      }

      // Find and clean up other log files
      const logFiles = this.findLogFiles(PROJECT_ROOT);
      for (const logFile of logFiles) {
        try {
          const stats = statSync(logFile);
          const cutoffDate = new Date();
          cutoffDate.setDate(cutoffDate.getDate() - MAX_AGE_DAYS);

          if (stats.mtime < cutoffDate) {
            unlinkSync(logFile);
            this.stats.deletedFiles++;
            this.stats.totalSpaceSaved += stats.size;
            console.log(`  üóëÔ∏è  Deleted old log: ${logFile} (${this.formatBytes(stats.size)})`);
          }
        } catch (error) {
          // Skip files we can't process
        }
      }
    } catch (error) {
      this.stats.errors.push(`Failed to cleanup log files: ${error}`);
    }
  }

  private async cleanupNodeModulesLogs(): Promise<void> {
    console.log("üì¶ Cleaning up node_modules logs...");

    try {
      // Find and delete yarn-error.log files in node_modules
      const command = `find ${PROJECT_ROOT}/node_modules -name "yarn-error.log" -type f -delete 2>/dev/null || true`;
      execSync(command, { stdio: "pipe" });

      // Find and delete npm-debug.log files
      const npmCommand = `find ${PROJECT_ROOT}/node_modules -name "npm-debug.log*" -type f -delete 2>/dev/null || true`;
      execSync(npmCommand, { stdio: "pipe" });

      console.log("  üßπ Cleaned up node_modules log files");
    } catch (error) {
      this.stats.errors.push(`Failed to cleanup node_modules logs: ${error}`);
    }
  }

  private findLogFiles(dir: string): string[] {
    const logFiles: string[] = [];

    try {
      const files = readdirSync(dir);
      for (const file of files) {
        const fullPath = join(dir, file);
        const stat = statSync(fullPath);

        if (stat.isDirectory() && !file.startsWith(".") && file !== "node_modules") {
          logFiles.push(...this.findLogFiles(fullPath));
        } else if (stat.isFile() && file.endsWith(".log")) {
          logFiles.push(fullPath);
        }
      }
    } catch (error) {
      // Skip directories we can't read
    }

    return logFiles;
  }

  private formatBytes(bytes: number): string {
    if (bytes === 0) return "0 B";
    const k = 1024;
    const sizes = ["B", "KB", "MB", "GB"];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + " " + sizes[i];
  }

  /**
   * Clean up user logs
   */
  private async cleanupUserLogs(): Promise<void> {
    console.log("üë§ Cleaning up user logs...");

    try {
      await UserLogger.cleanupOldLogs();
      console.log("  üßπ User logs cleanup completed");
    } catch (error) {
      this.stats.errors.push(`Failed to cleanup user logs: ${error}`);
    }
  }

  private displaySummary(): void {
    console.log("\nüìä Cleanup Summary:");
    console.log(`  üóëÔ∏è  Files deleted: ${this.stats.deletedFiles}`);
    console.log(`  ‚úÇÔ∏è  Files truncated: ${this.stats.truncatedFiles}`);
    console.log(`  üíæ Space saved: ${this.formatBytes(this.stats.totalSpaceSaved)}`);

    if (this.stats.errors.length > 0) {
      console.log(`  ‚ö†Ô∏è  Errors: ${this.stats.errors.length}`);
      this.stats.errors.forEach((error) => console.log(`    - ${error}`));
    }

    console.log("\n‚úÖ Cleanup completed successfully!");
  }
}

// Run the cleanup if this script is executed directly
if (require.main === module) {
  const cleanup = new LogCleanup();
  cleanup.run().catch(console.error);
}

export { LogCleanup };
